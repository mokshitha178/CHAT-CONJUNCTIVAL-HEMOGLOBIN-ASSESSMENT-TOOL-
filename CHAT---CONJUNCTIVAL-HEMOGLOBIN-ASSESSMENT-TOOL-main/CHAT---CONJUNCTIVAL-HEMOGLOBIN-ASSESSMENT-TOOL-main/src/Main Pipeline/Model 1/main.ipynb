{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image saved as 'C:\\Users\\Deepak\\Documents\\major projecct(rean)\\Source code (VS)\\pipeline\\model 1\\captured images\\captured_image_1.jpg'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import os\n",
    "\n",
    "# Initialize the camera\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "# Define the box coordinates\n",
    "box_start = (150, 100)  # Top-left corner of the box\n",
    "box_end = (400, 300)    # Bottom-right corner of the box\n",
    "\n",
    "# Initialize image counter\n",
    "img_counter = 1\n",
    "\n",
    "# Specify the folder where images will be saved\n",
    "save_folder = r'Captured_Images_Folder\"\n",
    "\n",
    "# Create the folder if it doesn't exist\n",
    "if not os.path.exists(save_folder):\n",
    "    os.makedirs(save_folder)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    # Draw the box on the frame\n",
    "    cv2.rectangle(frame, box_start, box_end, (0, 255, 0), 2)\n",
    "    cv2.putText(frame, \"Press 'c' to capture, 'q' to quit\", (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)\n",
    "\n",
    "    # Display the frame with the box\n",
    "    cv2.imshow(\"Camera\", frame)\n",
    "\n",
    "    # Check for key press\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "    if key == ord('c'):  # Press 'c' to capture the image inside the box\n",
    "        # Crop the image inside the box\n",
    "        cropped_image = frame[box_start[1]:box_end[1], box_start[0]:box_end[0]]\n",
    "        \n",
    "        # Save the captured image in the specified folder with a unique filename\n",
    "        filename = os.path.join(save_folder, f\"captured_image_{img_counter}.jpg\")\n",
    "        cv2.imwrite(filename, cropped_image)\n",
    "        print(f\"Image saved as '{filename}'\")\n",
    "        img_counter += 1  # Increment the counter for the next capture\n",
    "\n",
    "    elif key == ord('q'):  # Press 'q' to quit\n",
    "        break\n",
    "\n",
    "# Release the camera and close windows\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Segmentation Model (It segments the eye conjunctiva part from the real time image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape for model: (1, 256, 256, 3)\n",
      "1/1 [==============================] - 1s 805ms/step\n",
      "Saved segmented image: C:\\Users\\Deepak\\Documents\\major projecct(rean)\\Source code (VS)\\pipeline\\model 1\\segmented images\\segmented_1683272457169.jpg\n",
      "Input shape for model: (1, 256, 256, 3)\n",
      "1/1 [==============================] - 0s 79ms/step\n",
      "Saved segmented image: C:\\Users\\Deepak\\Documents\\major projecct(rean)\\Source code (VS)\\pipeline\\model 1\\segmented images\\segmented_1683518265539.jpg\n",
      "Input shape for model: (1, 256, 256, 3)\n",
      "1/1 [==============================] - 0s 61ms/step\n",
      "Saved segmented image: C:\\Users\\Deepak\\Documents\\major projecct(rean)\\Source code (VS)\\pipeline\\model 1\\segmented images\\segmented_1684219703477.jpg\n",
      "Input shape for model: (1, 256, 256, 3)\n",
      "1/1 [==============================] - 0s 62ms/step\n",
      "Saved segmented image: C:\\Users\\Deepak\\Documents\\major projecct(rean)\\Source code (VS)\\pipeline\\model 1\\segmented images\\segmented_a.png\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "\n",
    "def load_model(model_path):\n",
    "    \"\"\"Load a pre-trained U-Net model.\"\"\"\n",
    "    if not os.path.exists(model_path):\n",
    "        raise FileNotFoundError(f\"Model file not found at {model_path}\")\n",
    "    return tf.keras.models.load_model(model_path, compile=False)\n",
    "\n",
    "model_path = r'Segmentation_Model_Path'\n",
    "model = load_model(model_path)\n",
    "h = 256  # Image height\n",
    "w = 256  # Image width\n",
    "\n",
    "def predict_mask(model, eye_image):\n",
    "    \"\"\"Predict the mask for the given eye image.\"\"\"\n",
    "    img_input = np.expand_dims(eye_image, axis=0)\n",
    "    print(f\"Input shape for model: {np.shape(img_input)}\")\n",
    "    mask = model.predict(img_input)\n",
    "    return mask\n",
    "\n",
    "# Folder path containing eye images\n",
    "folder_path = r'Captured_Images_Path'\n",
    "output_folder = r'Segmented_Images_Path'\n",
    "\n",
    "# Process each image in the folder\n",
    "for image_name in os.listdir(folder_path):\n",
    "    if image_name.endswith(('.jpg', '.jpeg', '.png')):  # Ensure valid image formats\n",
    "        image_path = os.path.join(folder_path, image_name)\n",
    "\n",
    "        # Preprocess the image\n",
    "        eye_image = cv2.imread(image_path, cv2.IMREAD_COLOR)\n",
    "        eye_image = cv2.resize(eye_image, (w, h))\n",
    "        eye_image = cv2.cvtColor(eye_image, cv2.COLOR_BGR2RGB)  # Convert to RGB\n",
    "        eye_image = eye_image / 255.0  # Normalize to [0, 1]\n",
    "\n",
    "        # Predict the mask\n",
    "        mask = predict_mask(model, eye_image)\n",
    "        mask = mask * 255  # Scale mask values to [0, 255]\n",
    "        mask = np.squeeze(mask)  # Remove singleton dimensions\n",
    "\n",
    "        # Apply thresholding\n",
    "        ret, th1 = cv2.threshold(mask, 0.025 * 255, 255, cv2.THRESH_BINARY)\n",
    "        th1 = np.expand_dims(th1, axis=-1)  # Add back the channel dimension\n",
    "        th1 = th1 / 255.0  # Normalize thresholded mask\n",
    "\n",
    "        # Crop the eye image using the thresholded mask\n",
    "        cropped_eye_img = th1 * eye_image\n",
    "\n",
    "        # Scale the cropped image back to [0, 255] for saving\n",
    "        cropped_eye_img = (cropped_eye_img * 255).astype(np.uint8)\n",
    "\n",
    "        # Convert the cropped image back to BGR for saving with OpenCV\n",
    "        cropped_eye_img_bgr = cv2.cvtColor(cropped_eye_img, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "        # Save extracted conjunctiva image\n",
    "        save_path = os.path.join(output_folder, f\"segmented_{image_name}\")\n",
    "        cv2.imwrite(save_path, cropped_eye_img_bgr)\n",
    "\n",
    "        print(f\"Saved segmented image: {save_path}\")\n",
    "\n",
    "        # Display the cropped eye image\n",
    "        # plt.imshow(cropped_eye_img)  # Display in RGB format\n",
    "        # plt.title(f\"Cropped Eye Image for {image_name}\")\n",
    "        # # plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Classification Model ( It classifies the anemia condition and severity )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 10 calls to <function Model.make_predict_function.<locals>.predict_function at 0x00000170C55419E0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "1/1 [==============================] - 1s 789ms/step\n",
      "Image: segmented_1683272457169.jpg -> Predicted class: No Anemia\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "Image: segmented_1683518265539.jpg -> Predicted class: Moderate Anemia\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "Image: segmented_1684219703477.jpg -> Predicted class: Moderate Anemia\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Image: segmented_a.png -> Predicted class: Moderate Anemia\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from tensorflow.keras.models import load_model\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.mobilenet_v3 import preprocess_input\n",
    "\n",
    "# Define the preprocess_image function\n",
    "def preprocess_image(img_path, target_size=(224, 224)):\n",
    "    \n",
    "    # Load the image and resize it\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    \n",
    "    # Convert the image to a numpy array\n",
    "    img_array = image.img_to_array(img)\n",
    "    \n",
    "    # Expand dimensions to match the input shape (batch_size, 224, 224, 3)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    \n",
    "    # Preprocess the image using MobileNetV3's preprocessing function\n",
    "    img_array = preprocess_input(img_array)\n",
    "    \n",
    "    return img_array\n",
    "\n",
    "# Load the model\n",
    "# model = load_model(r'C:\\Users\\Deepak\\Documents\\major projecct(rean)\\Source code (VS)\\classification model\\model.h5')\n",
    "model = load_model(r'Classification_Model_Path')\n",
    "\n",
    "# Define class labels (replace with your actual class names)\n",
    "class_labels = ['Mild Anemia', 'Moderate Anemia', 'No Anemia', 'Severe Anemia']\n",
    "\n",
    "# Path to the folder containing images\n",
    "folder_path = r'Segmented_Images_Path'\n",
    "\n",
    "# Loop through all images in the folder\n",
    "for filename in os.listdir(folder_path):\n",
    "    # Check if the file is an image (you can add more extensions if needed)\n",
    "    if filename.endswith('.jpg') or filename.endswith('.png'):\n",
    "        # Full path to the image\n",
    "        img_path = os.path.join(folder_path, filename)\n",
    "        \n",
    "        # Preprocess the image\n",
    "        sample_image = preprocess_image(img_path)\n",
    "        \n",
    "        # Make a prediction\n",
    "        predictions = model.predict(sample_image)\n",
    "        \n",
    "        # Get the predicted class index\n",
    "        predicted_class_index = np.argmax(predictions, axis=1)[0]\n",
    "        \n",
    "        # Map the class index to the class name\n",
    "        predicted_class_name = class_labels[predicted_class_index]\n",
    "        if predicted_class_name == \"Mild Anemia\":\n",
    "            predicted_class_name = \"No Anemia\"\n",
    "        # Print the result\n",
    "        print(f\"Image: {filename} -> Predicted class: {predicted_class_name}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
